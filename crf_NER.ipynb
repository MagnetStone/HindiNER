{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "मैं\n",
      "भोपाल\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "मुंबई\n",
      "के\n",
      "दो\n",
      "टिकट\n",
      "दो\n",
      "क्या\n",
      "कल\n",
      "चेन्नई\n",
      "से\n",
      "पांडिचेरी\n",
      "तक\n",
      "कोई\n",
      "उड़ानें\n",
      "उपलब्ध\n",
      "हैं\n",
      "मैं\n",
      "दिल्ली\n",
      "जाना\n",
      "चाहता\n",
      "हूँ\n",
      "मुझे\n",
      "दिल्ली\n",
      "से\n",
      "औरंगाबाद\n",
      "की\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "दो\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "मैं\n",
      "इंग्लैंड\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "अगले\n",
      "महीने\n",
      "अमेरिका\n",
      "की\n",
      "टिकट\n",
      "कीमतों\n",
      "को\n",
      "दिखाएं\n",
      "मैं\n",
      "110702\n",
      "को\n",
      "मुंबई\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मैं\n",
      "कल\n",
      "\n",
      "गुवाहाटी\n",
      "में\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "परसों\n",
      "इंदौर\n",
      "में\n",
      "होना\n",
      "चाहिए\n",
      "मुझे\n",
      "न्यूयॉर्क\n",
      "जाने\n",
      "की\n",
      "जरूरत\n",
      "है\n",
      "मुझे\n",
      "गोवा\n",
      "ले\n",
      "जाओ\n",
      "मैं\n",
      "परसों\n",
      "नागपुर\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "कल\n",
      "मुंबई\n",
      "से\n",
      "श्रीनगर\n",
      "के\n",
      "लिए\n",
      "4\n",
      "टिकट\n",
      "बुक\n",
      "करें।\n",
      "मैं\n",
      "कल\n",
      "दिल्ली\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "1\n",
      "तारीख\n",
      "की\n",
      "इंदौर\n",
      "से\n",
      "चेन्नई\n",
      "के\n",
      "लिए\n",
      "4\n",
      "टिकटों\n",
      "की\n",
      "बुकिंग\n",
      "करें\n",
      "मैं\n",
      "बेंगलुरु\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "अगले\n",
      "सप्ताह\n",
      "अमेरिका\n",
      "में\n",
      "होना\n",
      "चाहिए\n",
      "मुझे\n",
      "इंग्लैंड\n",
      "जाने\n",
      "की\n",
      "ज़रूरत\n",
      "है\n",
      "कल\n",
      "दिल्ली\n",
      "के\n",
      "लिए\n",
      "एक\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "जयपुर\n",
      "से\n",
      "लखनऊ\n",
      "तक\n",
      "22\n",
      "वीं\n",
      "की\n",
      "कोई\n",
      "बस\n",
      "है\n",
      "दिल्ली\n",
      "की\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "एक\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "क्या\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "मुंबई\n",
      "में\n",
      "कोई\n",
      "टिकट\n",
      "उपलब्ध\n",
      "है\n",
      "मुझे\n",
      "बॉम्बे\n",
      "ले\n",
      "आओ\n",
      "मुझे\n",
      "सिडनी\n",
      "जाना\n",
      "है\n",
      "कल\n",
      "लखनऊ\n",
      "की\n",
      "कोई\n",
      "भी\n",
      "उड़ानें\n",
      "मैं\n",
      "कल\n",
      "मुंबई\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n"
     ]
    }
   ],
   "source": [
    "import features #functions defining word features\n",
    "import data_parser #function(s) to load train and test data from .txt files\n",
    "import cPickle as pickle\n",
    "import pprint\n",
    "\n",
    "freq=features.frequencies('train.txt') #returns a dictionary of word frequencies in the file\n",
    "\n",
    "train_sents=data_parser.load('train.txt')\n",
    "test_sents=data_parser.load('test.txt')\n",
    "#sents is a list of lists, each list corresponding to a sentence in the 'train.txt'\n",
    "#The list has the format (word,category,label) for each word in sentence, each label corresponding to\n",
    "#the entity of the word. For current training datasets, these are-\n",
    "#(Date-Date, Num-Number of tickets, Dest-Destination, Src-Source Location)\n",
    "#category is retreived from the Hindi WordNet database,return N for noun,\n",
    "#V for verb,AV for adverb and AJ for adjective. Return X if not found in the database \n",
    "print len(train_sents)\n",
    "for i in train_sents:\n",
    "    for x in i:\n",
    "        print(x[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    category = sent[i][1]\n",
    "    if(word not in freq): freq[word]=0\n",
    "    feat = [\n",
    "        'bias',\n",
    "        'word=' + word,\n",
    "        'word.isdigit=%s' % features.isdigit(word),\n",
    "        'category=' + str(category),\n",
    "        'freq='+ str(freq[word]),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        if(word1 not in freq): freq[word1]=0\n",
    "        category1 = sent[i-1][1]\n",
    "        feat.extend([\n",
    "            '-1:word=' + word,\n",
    "            '-1:word.isdigit=%s' % features.isdigit(word1),\n",
    "            '-1:category=' + str(category1),\n",
    "            '-1:freq='+ str(freq[word1]),\n",
    "        ])\n",
    "    else:\n",
    "        feat.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        if(word1 not in freq): freq[word1]=0\n",
    "        category1 = sent[i+1][1]\n",
    "        feat.extend([\n",
    "            '+1:word=' + word,\n",
    "            '+1:word.isdigit=%s' % features.isdigit(word1),\n",
    "            '+1:category=' + str(category1),\n",
    "            '+1:freq='+ str(freq[word1]),\n",
    "        ])\n",
    "    else:\n",
    "        feat.append('EOS')\n",
    "                \n",
    "    return feat\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for word, category, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for word,postag,label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word=\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82',\n",
       " 'word.isdigit=False',\n",
       " 'category=X',\n",
       " 'freq=9',\n",
       " 'BOS',\n",
       " '+1:word=\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82',\n",
       " '+1:word.isdigit=False',\n",
       " '+1:category=X',\n",
       " '+1:freq=1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'D', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "print y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params() #List set of possible params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 8 ms, total: 60 ms\n",
      "Wall time: 47.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('hindiNER.crfsuite') #train and save model to file 'hindiNER.crfsuite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fd7b3a01350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('hindiNER.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कैनबरा के लिए टिकट बुक करें\n",
      "('Predicted:', '0 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0')\n",
      "मुंबई से गुवाहाटी तक सबसे सस्ता किराया क्या है\n",
      "('Predicted:', 'S 0 D 0 0 0 0 S 0')\n",
      "('Correct:  ', 'S 0 D 0 0 0 0 0 0')\n",
      "दिल्ली के लिए टिकटों की जांच करें\n",
      "('Predicted:', 'D 0 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0 0')\n",
      "मुझे सिडनी ले जाएं\n",
      "('Predicted:', '0 0 0 0')\n",
      "('Correct:  ', '0 D 0 0')\n",
      "अगले महीने लंदन के टिकटों की कीमत दिखाएं\n",
      "('Predicted:', '0 0 0 0 0 0 0 0')\n",
      "('Correct:  ', '0 0 D 0 0 0 0 0')\n",
      "चेन्नई के लिए टिकट बुक करें\n",
      "('Predicted:', '0 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0')\n",
      "मुझे अगले महीने मुंबई के टिकटों की कीमत दिखाएं\n",
      "('Predicted:', '0 0 0 D 0 0 0 0 0')\n",
      "('Correct:  ', '0 0 0 D 0 0 0 0 0')\n"
     ]
    }
   ],
   "source": [
    "for i in test_sents:\n",
    "    example_sent = i#test_sents[0]\n",
    "    print(' '.join(sent2tokens(example_sent)))\n",
    "    print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "    print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us check what the classifier learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "D      -> 0       1.725437\n",
      "T      -> D       0.882015\n",
      "0      -> D       0.116878\n",
      "S      -> 0       0.082172\n",
      "0      -> T       0.070536\n",
      "T      -> S       0.032156\n",
      "T      -> 0       -0.064591\n",
      "0      -> 0       -0.156190\n",
      "0      -> S       -0.456525\n",
      "\n",
      "Top unlikely transitions:\n",
      "D      -> 0       1.725437\n",
      "T      -> D       0.882015\n",
      "0      -> D       0.116878\n",
      "S      -> 0       0.082172\n",
      "0      -> T       0.070536\n",
      "T      -> S       0.032156\n",
      "T      -> 0       -0.064591\n",
      "0      -> 0       -0.156190\n",
      "0      -> S       -0.456525\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "3.320278 S      +1:freq=5\n",
      "2.665667 N      -1:freq=7\n",
      "1.944542 D      +1:freq=10\n",
      "1.898065 T      word=कल\n",
      "1.898065 T      freq=11\n",
      "1.898065 T      +1:word=कल\n",
      "1.883103 0      freq=9\n",
      "1.828114 N      +1:freq=7\n",
      "1.512897 D      -1:freq=5\n",
      "1.364915 0      bias\n",
      "1.364915 0      category=X\n",
      "1.334110 0      -1:freq=1\n",
      "1.273273 T      -1:freq=9\n",
      "1.206931 0      word.isdigit=False\n",
      "1.165126 0      +1:freq=1\n",
      "1.008999 0      -1:freq=4\n",
      "0.994211 0      freq=4\n",
      "0.945364 0      freq=10\n",
      "0.875313 0      EOS\n",
      "0.865102 0      freq=8\n",
      "\n",
      "Top negative:\n",
      "0.504537 D      +1:freq=8\n",
      "0.266940 D      +1:freq=9\n",
      "0.246206 D      -1:word=अमेरिका\n",
      "0.246206 D      word=अमेरिका\n",
      "0.246206 D      +1:word=अमेरिका\n",
      "0.155730 0      -1:category=X\n",
      "0.046218 D      word=मुंबई\n",
      "0.046218 D      -1:word=मुंबई\n",
      "0.046218 D      +1:word=मुंबई\n",
      "0.007354 0      -1:word=से\n",
      "0.007354 0      word=से\n",
      "0.007354 0      +1:word=से\n",
      "0.003408 D      word=इंग्लैंड\n",
      "0.003408 D      -1:word=इंग्लैंड\n",
      "0.003408 D      +1:word=इंग्लैंड\n",
      "-0.115082 D      -1:freq=9\n",
      "-0.543756 N      word.isdigit=False\n",
      "-0.819478 0      -1:freq=10\n",
      "-1.009120 0      freq=5\n",
      "-1.117018 0      freq=2\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
