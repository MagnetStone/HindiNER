{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "मैं\n",
      "भोपाल\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "मुंबई\n",
      "के\n",
      "दो\n",
      "टिकट\n",
      "दो\n",
      "क्या\n",
      "कल\n",
      "चेन्नई\n",
      "से\n",
      "पांडिचेरी\n",
      "तक\n",
      "कोई\n",
      "उड़ानें\n",
      "उपलब्ध\n",
      "हैं\n",
      "मैं\n",
      "दिल्ली\n",
      "जाना\n",
      "चाहता\n",
      "हूँ\n",
      "मुझे\n",
      "दिल्ली\n",
      "से\n",
      "औरंगाबाद\n",
      "की\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "दो\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "मैं\n",
      "इंग्लैंड\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "अगले\n",
      "महीने\n",
      "अमेरिका\n",
      "की\n",
      "टिकट\n",
      "कीमतों\n",
      "को\n",
      "दिखाएं\n",
      "मैं\n",
      "110702\n",
      "को\n",
      "मुंबई\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मैं\n",
      "कल\n",
      "\n",
      "गुवाहाटी\n",
      "में\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "परसों\n",
      "इंदौर\n",
      "में\n",
      "होना\n",
      "चाहिए\n",
      "मुझे\n",
      "न्यूयॉर्क\n",
      "जाने\n",
      "की\n",
      "जरूरत\n",
      "है\n",
      "मुझे\n",
      "गोवा\n",
      "ले\n",
      "जाओ\n",
      "मैं\n",
      "परसों\n",
      "नागपुर\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "कल\n",
      "मुंबई\n",
      "से\n",
      "श्रीनगर\n",
      "के\n",
      "लिए\n",
      "4\n",
      "टिकट\n",
      "बुक\n",
      "करें।\n",
      "मैं\n",
      "कल\n",
      "दिल्ली\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "1\n",
      "तारीख\n",
      "की\n",
      "इंदौर\n",
      "से\n",
      "चेन्नई\n",
      "के\n",
      "लिए\n",
      "4\n",
      "टिकटों\n",
      "की\n",
      "बुकिंग\n",
      "करें\n",
      "मैं\n",
      "बेंगलुरु\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n",
      "मुझे\n",
      "अगले\n",
      "सप्ताह\n",
      "अमेरिका\n",
      "में\n",
      "होना\n",
      "चाहिए\n",
      "मुझे\n",
      "इंग्लैंड\n",
      "जाने\n",
      "की\n",
      "ज़रूरत\n",
      "है\n",
      "कल\n",
      "दिल्ली\n",
      "के\n",
      "लिए\n",
      "एक\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "जयपुर\n",
      "से\n",
      "लखनऊ\n",
      "तक\n",
      "22\n",
      "वीं\n",
      "की\n",
      "कोई\n",
      "बस\n",
      "है\n",
      "दिल्ली\n",
      "की\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "एक\n",
      "टिकट\n",
      "बुक\n",
      "करें\n",
      "क्या\n",
      "कल\n",
      "के\n",
      "लिए\n",
      "मुंबई\n",
      "में\n",
      "कोई\n",
      "टिकट\n",
      "उपलब्ध\n",
      "है\n",
      "मुझे\n",
      "बॉम्बे\n",
      "ले\n",
      "आओ\n",
      "मुझे\n",
      "सिडनी\n",
      "जाना\n",
      "है\n",
      "कल\n",
      "लखनऊ\n",
      "की\n",
      "कोई\n",
      "भी\n",
      "उड़ानें\n",
      "मैं\n",
      "कल\n",
      "मुंबई\n",
      "जाना\n",
      "चाहता\n",
      "हूं\n"
     ]
    }
   ],
   "source": [
    "import features #functions defining word features\n",
    "import data_parser #function(s) to load train and test data from .txt files\n",
    "import cPickle as pickle\n",
    "import pprint\n",
    "\n",
    "freq=features.frequencies('train.txt') #returns a dictionary of word frequencies in the file\n",
    "\n",
    "train_sents=data_parser.load('train.txt')\n",
    "test_sents=data_parser.load('test.txt')\n",
    "#sents is a list of lists, each list corresponding to a sentence in the 'train.txt'\n",
    "#The list has the format (word,category,label) for each word in sentence, each label corresponding to\n",
    "#the entity of the word. For current training datasets, these are-\n",
    "#(Date-Date, Num-Number of tickets, Dest-Destination, Src-Source Location)\n",
    "#category is retreived from the Hindi WordNet database,return N for noun,\n",
    "#V for verb,AV for adverb and AJ for adjective. Return X if not found in the database \n",
    "print len(train_sents)\n",
    "for i in train_sents:\n",
    "    for x in i:\n",
    "        print(x[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    category = sent[i][1]\n",
    "    if(word not in freq): freq[word]=0\n",
    "    feat = [\n",
    "        'bias',\n",
    "        'word=' + word,\n",
    "        'word.isdigit=%s' % features.isdigit(word),\n",
    "        'category=' + str(category),\n",
    "        'freq='+ str(freq[word]),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        if(word1 not in freq): freq[word1]=0\n",
    "        category1 = sent[i-1][1]\n",
    "        feat.extend([\n",
    "            '-1:word=' + word,\n",
    "            '-1:word.isdigit=%s' % features.isdigit(word1),\n",
    "            '-1:category=' + str(category1),\n",
    "            '-1:freq='+ str(freq[word1]),\n",
    "        ])\n",
    "    else:\n",
    "        feat.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        if(word1 not in freq): freq[word1]=0\n",
    "        category1 = sent[i+1][1]\n",
    "        feat.extend([\n",
    "            '+1:word=' + word,\n",
    "            '+1:word.isdigit=%s' % features.isdigit(word1),\n",
    "            '+1:category=' + str(category1),\n",
    "            '+1:freq='+ str(freq[word1]),\n",
    "        ])\n",
    "    else:\n",
    "        feat.append('EOS')\n",
    "                \n",
    "    return feat\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for word, category, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for word,postag,label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word=\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82',\n",
       " 'word.isdigit=False',\n",
       " 'category=X',\n",
       " 'freq=9',\n",
       " 'BOS',\n",
       " '+1:word=\\xe0\\xa4\\xae\\xe0\\xa5\\x88\\xe0\\xa4\\x82',\n",
       " '+1:word.isdigit=False',\n",
       " '+1:category=N',\n",
       " '+1:freq=1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'D', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "print y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params() #List set of possible params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 4 ms, total: 40 ms\n",
      "Wall time: 36.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('hindiNER.crfsuite') #train and save model to file 'hindiNER.crfsuite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f22f96efc10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('hindiNER.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कैनबरा के लिए टिकट बुक करें\n",
      "('Predicted:', '0 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0')\n",
      "मुंबई से गुवाहाटी तक सबसे सस्ता किराया क्या है\n",
      "('Predicted:', 'S 0 D 0 0 0 0 0 0')\n",
      "('Correct:  ', 'S 0 D 0 0 0 0 0 0')\n",
      "दिल्ली के लिए टिकटों की जांच करें\n",
      "('Predicted:', 'D 0 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0 0')\n",
      "मुझे सिडनी ले जाएं\n",
      "('Predicted:', '0 D 0 0')\n",
      "('Correct:  ', '0 D 0 0')\n",
      "अगले महीने लंदन के टिकटों की कीमत दिखाएं\n",
      "('Predicted:', '0 0 0 0 0 0 0 0')\n",
      "('Correct:  ', '0 0 D 0 0 0 0 0')\n",
      "चेन्नई के लिए टिकट बुक करें\n",
      "('Predicted:', 'D 0 0 0 0 0')\n",
      "('Correct:  ', 'D 0 0 0 0 0')\n",
      "मुझे अगले महीने मुंबई के टिकटों की कीमत दिखाएं\n",
      "('Predicted:', '0 0 0 D 0 0 0 0 0')\n",
      "('Correct:  ', '0 0 0 D 0 0 0 0 0')\n"
     ]
    }
   ],
   "source": [
    "for i in test_sents:\n",
    "    example_sent = i#test_sents[0]\n",
    "    print(' '.join(sent2tokens(example_sent)))\n",
    "    print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "    print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us check what the classifier learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "T      -> D       1.589825\n",
      "D      -> 0       0.944340\n",
      "T      -> 0       -0.023198\n",
      "0      -> S       -0.160810\n",
      "\n",
      "Top unlikely transitions:\n",
      "T      -> D       1.589825\n",
      "D      -> 0       0.944340\n",
      "T      -> 0       -0.023198\n",
      "0      -> S       -0.160810\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "4.259556 S      +1:category=AV\n",
      "3.741616 0      word.isdigit=False\n",
      "2.499944 N      -1:freq=7\n",
      "2.140822 0      category=X\n",
      "1.861715 0      -1:category=N\n",
      "1.673121 T      word=कल\n",
      "1.673121 T      freq=11\n",
      "1.673121 T      +1:word=कल\n",
      "1.452345 D      freq=5\n",
      "1.361314 D      category=N\n",
      "1.327692 T      -1:freq=9\n",
      "1.291521 S      +1:freq=5\n",
      "1.169535 D      -1:category=AV\n",
      "1.168447 N      +1:freq=7\n",
      "0.993123 0      +1:freq=1\n",
      "0.956118 D      +1:freq=10\n",
      "0.827742 0      -1:freq=1\n",
      "0.708166 D      freq=1\n",
      "0.493348 0      freq=9\n",
      "0.436128 T      word=परसों\n",
      "\n",
      "Top negative:\n",
      "0.956118 D      +1:freq=10\n",
      "0.827742 0      -1:freq=1\n",
      "0.708166 D      freq=1\n",
      "0.493348 0      freq=9\n",
      "0.436128 T      word=परसों\n",
      "0.436128 T      -1:word=परसों\n",
      "0.436128 T      +1:word=परसों\n",
      "0.254701 0      freq=7\n",
      "0.114313 D      -1:word=अमेरिका\n",
      "0.114313 D      word=अमेरिका\n",
      "0.114313 D      +1:word=अमेरिका\n",
      "0.063802 D      +1:freq=4\n",
      "0.063443 T      +1:freq=2\n",
      "0.054457 D      +1:category=N\n",
      "-0.037341 D      -1:freq=9\n",
      "-0.188222 0      +1:freq=8\n",
      "-0.400439 0      -1:freq=10\n",
      "-0.453948 0      freq=5\n",
      "-0.955312 0      category=N\n",
      "-1.463632 0      freq=2\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
